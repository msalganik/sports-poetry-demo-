# Sports Poetry Multi-Agent Workflow - Final Specification

**Version**: 1.0
**Date**: 2025-11-01
**Purpose**: Demonstrate coordinated multi-agent workflow with full auditability and provenance

---

## Overview

A demonstration of Claude Code's agentic capabilities where multiple specialized agents work in parallel to generate creative content, coordinated by a Python orchestrator with comprehensive logging.

---

## Architecture

```
User ↔ Claude (conversational input collection)
         ↓ writes
    config.json
         ↓ read by
  orchestrator.py
         ↓ launches
    ┌────┴────┬────────┬────────┐
    ▼         ▼        ▼        ▼
Agent 1   Agent 2  Agent 3  Agent N  (parallel execution)
(sport1)  (sport2) (sport3) (sportN)
    │         │        │        │
    └────┬────┴────────┴────────┘
         ▼ after all complete
   Analyzer Agent (synthesis)
         ↓ writes
  analysis_report.md
         ↓
  execution_log.jsonl (provenance)
  usage_log.jsonl (analytics)
```

---

## Specification Decisions

### 1. Input Collection Method
**Decision**: Natural conversational dialogue with Claude

**Implementation**:
- Claude asks user: "Which 3-5 sports would you like poems about?"
- User responds in natural language (any format)
- Claude validates:
  - Count: exactly 3-5 sports
  - No duplicates
  - Non-empty strings
- Claude confirms list with user
- Upon confirmation, Claude writes `config.json`

### 2. Error Handling Strategy
**Decision**: Graceful degradation + detailed logging + optional retry

**Implementation**:
```python
for sport in sports:
    try:
        result = launch_poetry_agent(sport)
        if result.failed and RETRY_ENABLED:
            log_event("orchestrator", "retry_agent", {"sport": sport})
            result = launch_poetry_agent(sport)
        results[sport] = result
    except Exception as e:
        log_event("orchestrator", "agent_failed", {"sport": sport, "error": str(e)})
        results[sport] = {"status": "failed", "error": str(e)}
        # Continue to next sport
```

**Behavior**:
- Each agent attempted once
- Optional single retry on failure (configurable)
- Workflow continues regardless of failures
- All failures logged to `execution_log.jsonl`
- Final analyzer notes missing/failed sports in report

### 3. Config File Format
**Decision**: JSON

**Structure**:
```json
{
  "sports": ["basketball", "soccer", "tennis"],
  "timestamp": "2025-11-01T14:23:00Z",
  "session_id": "abc123",
  "retry_enabled": true
}
```

**Rationale**:
- Consistent with JSONL logs
- Zero dependencies (Python stdlib)
- Strict syntax catches errors early
- Universal compatibility

### 4. Poetry Constraints
**Decision**: Attempt strict, accept creative

**Prompts**:
- Haiku: Request 5-7-5 syllable structure, 3 lines
- Sonnet: Request 14 lines, iambic pentameter, rhyme scheme
- **No validation/rejection** - accept whatever is produced
- Final analyzer comments on form adherence

**Rationale**:
- Shows prompt engineering best practices
- Avoids workflow failures on technicalities
- Creates interesting analysis data
- Realistic (LLMs imperfect at syllable counting)

### 5. Implementation Language
**Decision**: Hybrid - Python orchestrator + Claude coordination

**Responsibilities**:
- **Claude**:
  - Conversational input collection
  - Writes `config.json`
  - Launches `orchestrator.py`
  - Monitors progress

- **Python (`orchestrator.py`)**:
  - Reads `config.json`
  - Launches subagents (via subprocess/API)
  - Manages parallel execution
  - Captures agent outputs
  - Writes `execution_log.jsonl` (detailed provenance)
  - Writes `usage_log.jsonl` (aggregate analytics)
  - Launches analyzer agent
  - Handles errors gracefully

**Rationale**:
- Full auditability and provenance
- Structured logging with exact timestamps
- Per-agent attribution
- Reproducible from config
- Agent output capture

### 6. Agent Verbosity
**Decision**: Simple status updates

**Format**:
```
Agent basketball: Starting poetry generation
Agent basketball: Wrote haiku (3 lines)
Agent basketball: Wrote sonnet (14 lines)
Agent basketball: Complete
```

**Logging**:
Each status logged to `execution_log.jsonl`:
```json
{
  "timestamp": 1730476980.123,
  "actor": "agent_basketball",
  "action": "status",
  "message": "Wrote haiku (3 lines)"
}
```

---

## File Structure

```
sports_poetry_demo/
├── config.json                  # Generated by Claude from user input
├── orchestrator.py              # Main workflow coordinator
├── execution_log.jsonl          # Detailed provenance (every action)
├── usage_log.jsonl              # Aggregate analytics (per run)
├── README.md                    # Instructions and documentation
├── SPEC.md                      # This file
└── output/
    ├── basketball/
    │   ├── haiku.txt
    │   ├── sonnet.txt
    │   └── metadata.json        # Timestamps, word counts, etc.
    ├── soccer/
    │   ├── haiku.txt
    │   ├── sonnet.txt
    │   └── metadata.json
    ├── tennis/
    │   └── ...
    └── analysis_report.md       # Final synthesis from analyzer
```

---

## Workflow Phases

### Phase 1: Conversational Input Collection
1. Claude asks user for 3-5 sports
2. User responds naturally
3. Claude validates and confirms
4. Claude writes `config.json` with:
   - `sports`: list of sport names
   - `timestamp`: ISO 8601 timestamp
   - `session_id`: unique identifier
   - `retry_enabled`: boolean flag

### Phase 2: Orchestrator Initialization
1. Claude launches `orchestrator.py`
2. Orchestrator reads `config.json`
3. Logs: `{"actor": "orchestrator", "action": "read_config", "details": {...}}`
4. Creates `output/` directory structure

### Phase 3: Parallel Poetry Generation
For each sport (in parallel):
1. Orchestrator launches poetry agent (subprocess/API)
2. Logs: `{"actor": "orchestrator", "action": "launch_agent", "details": {"sport": "...", "pid": ...}}`
3. Agent creates `output/{sport}/` directory
4. Agent generates haiku (5-7-5 attempt)
5. Agent logs: `{"actor": "agent_{sport}", "action": "status", "message": "Wrote haiku (3 lines)"}`
6. Agent writes `haiku.txt`
7. Agent generates sonnet (14 lines attempt)
8. Agent logs: `{"actor": "agent_{sport}", "action": "status", "message": "Wrote sonnet (14 lines)"}`
9. Agent writes `sonnet.txt`
10. Agent writes `metadata.json` with:
    - `sport`: name
    - `timestamp_start`: when agent started
    - `timestamp_end`: when agent finished
    - `haiku_lines`: line count
    - `haiku_words`: word count
    - `sonnet_lines`: line count
    - `sonnet_words`: word count
11. Agent logs: `{"actor": "agent_{sport}", "action": "complete", "duration_s": ...}`

### Phase 4: Synchronization
1. Orchestrator waits for all agents to complete
2. Logs: `{"actor": "orchestrator", "action": "agents_complete", "details": {"total": N, "succeeded": M, "failed": K}}`
3. Verifies expected files exist

### Phase 5: Analysis & Synthesis
1. Orchestrator launches analyzer agent
2. Logs: `{"actor": "orchestrator", "action": "launch_analyzer"}`
3. Analyzer reads all poems from `output/*/`
4. Analyzer compares:
   - Themes and imagery
   - Tone and style
   - Form adherence (5-7-5 for haiku, 14 lines for sonnet)
   - Creativity and originality
5. Analyzer identifies:
   - Best haiku (with justification)
   - Best sonnet (with justification)
   - Best overall sport poems
6. Analyzer writes `output/analysis_report.md`:
   - Executive summary
   - Per-sport analysis
   - Comparative analysis
   - Rankings with justifications
   - Notes on failed/missing sports
   - Overall observations
7. Analyzer logs: `{"actor": "analyzer", "action": "complete"}`

### Phase 6: Usage Logging
1. Orchestrator aggregates all execution data
2. Writes single entry to `usage_log.jsonl`:
```json
{
  "session_id": "abc123",
  "timestamp": "2025-11-01T14:23:00Z",
  "sports": ["basketball", "soccer", "tennis"],
  "sports_count": 3,
  "validation": "pass",
  "agents_launched": 3,
  "agents_succeeded": 3,
  "agents_failed": 0,
  "agent_results": [
    {
      "sport": "basketball",
      "status": "success",
      "duration_s": 12.4,
      "haiku_lines": 3,
      "sonnet_lines": 14
    },
    {
      "sport": "soccer",
      "status": "success",
      "duration_s": 15.2,
      "haiku_lines": 3,
      "sonnet_lines": 14
    },
    {
      "sport": "tennis",
      "status": "success",
      "duration_s": 11.8,
      "haiku_lines": 3,
      "sonnet_lines": 14
    }
  ],
  "analyzer_duration_s": 8.3,
  "total_duration_s": 47.7,
  "errors": [],
  "retry_count": 0
}
```

---

## Logging Strategy

### execution_log.jsonl (Detailed Provenance)
- **Purpose**: Complete audit trail of every action
- **Format**: One JSON object per line, one line per event
- **Append-only**: Never overwrite, always append
- **Fields**:
  - `timestamp`: Unix timestamp (float)
  - `actor`: Who performed action (orchestrator, agent_{sport}, analyzer)
  - `action`: What was done (read_config, launch_agent, write_file, status, complete, error)
  - `details`: Action-specific data (varies by action type)
  - `message`: Human-readable description (optional)

**Example**:
```jsonl
{"timestamp": 1730476980.123, "actor": "orchestrator", "action": "read_config", "details": {"sports": ["basketball", "soccer"]}}
{"timestamp": 1730476980.456, "actor": "orchestrator", "action": "launch_agent", "details": {"sport": "basketball", "pid": 1234}}
{"timestamp": 1730476982.789, "actor": "agent_basketball", "action": "status", "message": "Wrote haiku (3 lines)"}
{"timestamp": 1730476985.012, "actor": "agent_basketball", "action": "complete", "details": {"duration_s": 4.556}}
```

### usage_log.jsonl (Aggregate Analytics)
- **Purpose**: High-level statistics for pattern analysis
- **Format**: One JSON object per line, one line per workflow run
- **Use cases**:
  - Identify common failure patterns
  - Track performance trends
  - Analyze popular sports choices
  - Measure form adherence rates

---

## Agent Prompting Guidelines

### Poetry Agent Prompt Template
```
You are a poetry generation agent for the sport: {SPORT}

Your task:
1. Create a haiku about {SPORT}
   - Target: 5-7-5 syllable structure
   - 3 lines total
   - Capture essence of the sport

2. Create a sonnet about {SPORT}
   - Target: 14 lines
   - Attempt iambic pentameter
   - Consider traditional rhyme scheme (ABAB CDCD EFEF GG or similar)
   - Explore deeper themes of the sport

Output format:
- Write haiku to: output/{SPORT}/haiku.txt
- Write sonnet to: output/{SPORT}/sonnet.txt
- Write metadata to: output/{SPORT}/metadata.json

Log your progress with status updates:
- "Starting poetry generation"
- "Wrote haiku (N lines)"
- "Wrote sonnet (N lines)"
- "Complete"
```

### Analyzer Agent Prompt Template
```
You are an analysis agent evaluating poetry about multiple sports.

Your task:
1. Read all haiku and sonnets from output/*/
2. Analyze each sport's poems:
   - Theme and imagery
   - Tone and emotional resonance
   - Form adherence (5-7-5 for haiku, 14 lines for sonnet)
   - Creativity and originality
   - Technical execution

3. Perform comparative analysis:
   - Which haiku is best? Why?
   - Which sonnet is best? Why?
   - Which sport was captured most effectively?
   - Overall quality trends

4. Write comprehensive report to output/analysis_report.md

Format:
- Use markdown
- Include executive summary
- Per-sport analysis sections
- Comparative analysis
- Rankings with justifications
- Note any missing/failed sports

Be specific, cite examples, and justify your assessments.
```

---

## Success Criteria

A successful run produces:
1. ✅ `config.json` with validated sports list
2. ✅ One directory per sport in `output/`
3. ✅ `haiku.txt` and `sonnet.txt` for each sport (or logged failure)
4. ✅ `metadata.json` for each sport
5. ✅ `analysis_report.md` with comparative analysis
6. ✅ `execution_log.jsonl` with complete provenance
7. ✅ `usage_log.jsonl` with aggregate entry
8. ✅ All errors logged, workflow completes gracefully

---

## Future Extensions

- **Web UI**: Real-time progress monitoring
- **More poetry forms**: Limerick, villanelle, free verse
- **Quality scoring**: Automated form validation (syllable counting)
- **Human feedback**: Rate poems, improve over time
- **Persistent storage**: Database for cross-run analysis
- **A/B testing**: Different prompting strategies
- **Parallel comparison**: Multiple LLMs generate poems for same sport

---

**End of Specification**
